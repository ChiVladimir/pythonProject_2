{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiVladimir/pythonProject_2/blob/master/%22%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5_%D0%BA%D0%BE%D0%BD%D1%86%D0%B5%D0%BF%D1%86%D0%B8%D0%B8_%D0%B8_%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F_%D0%98%D0%98_%D0%94_%D0%97_cvv_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "Ознакомьтесь с приведёнными ниже примерами использования алгоритмов МО и НС для решения задачи распознавания рукописных цифр.\n",
        "\n",
        "## Порядок выполнения ДЗ\n",
        "\n",
        "1. Сделайте копию данного блокнота себе на диск. Далее работайте со своей копией блокнота. Сохраняйте вносимые в неё изменения.\n",
        "2. Ознакомьтесь с теоретическим текстом и кодом из настоящего блокнота.\n",
        "3. Перенесите примеры кода в отдельные кодовые ячейки и выполните их.\n",
        "4. Создайте тестовую ячейку, куда запишите ответы на теоретические вопросы.\n",
        "5. Расшарьте блокнот и используйте ссылку как ответ на ДЗ."
      ],
      "metadata": {
        "id": "SeivPBkJjNUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Учебный пример: Решение задачи классификация рукописных цифр с использованием машинного обучения, глубокого обучения и нейронных сетей\n",
        "\n",
        "В этом задании мы будем использовать набор данных MNIST, который содержит изображения рукописных цифр (от 0 до 9). Мы реализуем три различных подхода к классификации этих изображений:\n",
        "\n",
        "1. **Машинное обучение**: Используем метод k-ближайших соседей (k-NN).\n",
        "2. **Глубокое обучение**: Используем многослойный перцептрон (MLP).\n",
        "3. **Нейронные сети**: Используем сверточную нейронную сеть (CNN).\n",
        "\n",
        "### Шаг 1: Установка библиотек\n",
        "\n",
        "Установите необходимые библиотеки:\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn tensorflow keras\n",
        "```\n",
        "\n",
        "### Шаг 2: Загрузка и предобработка данных\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### Шаг 3: Алгоритм машинного обучения (k-NN)\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 4: Глубокое обучение (MLP)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 5: Нейронные сети (CNN)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')\n",
        "```\n",
        "\n",
        "### Заключение\n",
        "\n",
        "В этом задании мы реализовали три различных подхода к классификации изображений рукописных цифр с использованием средств машинного обучения (k-NN), глубокого обучения (MLP) и нейронных сетей (CNN). Мы увидели, что каждый из этих подходов имеет свои преимущества и недостатки, и что сложные модели глубокого обучения могут значительно улучшить точность классификации по сравнению с простыми моделями машинного обучения.\n",
        "\n",
        "### Теоритические вопросы\n",
        "\n",
        "1. Какие преимущества и недостатки использованных методов вы увидели?\n",
        "2. В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n",
        "3. Какие методы предобработки данных были использованы в этом задании?\n"
      ],
      "metadata": {
        "id": "vGMR-kTge1Wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Шаг 1: Установка библиотек"
      ],
      "metadata": {
        "id": "PTSBi2vxQsW4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDsO7Qm5e0px",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44649de-c7fa-4178-e292-886e8f57e2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn tensorflow keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Шаг 2: Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "VLcbuBv9RBtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(fetch_openml('mnist_784').keys())\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int) # конвертирует метки в целочисленные значения\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hddlTSuhRH2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef72e78-de3d-44d0-b0d2-d2af08eb2fb0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попытка обхода неработающего openml (https://github.com/openml/openml.org/issues/343) - загрузка и предобработка данных.\n",
        "\n",
        "upd 27.01.25 - ресурс заработал, реализация исследования через альтернативный источник не дала корректного результата, оставлена, как дополнительный пример кода подготовки данных  "
      ],
      "metadata": {
        "id": "uiz31tBUPMYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "# скачиваем данные и разделяем на набор для обучения и тестовый\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "num_classes = 10\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# преобразование векторных классов в бинарные матрицы\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('Размерность X_train:', X_train.shape)\n",
        "print(X_train.shape[0], 'Размер train')\n",
        "print(X_test.shape[0], 'Размер test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgtVFn1PSin",
        "outputId": "a125b089-fa26-4cdd-b0ed-eeb6037ce54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "Размерность X_train: (60000, 28, 28, 1)\n",
            "60000 Размер train\n",
            "10000 Размер test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Шаг 3: Алгоритм машинного обучения (k-NN)"
      ],
      "metadata": {
        "id": "LF7DXC01KGcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKuZkUj-KFxI",
        "outputId": "c05f8c01-e0fb-4639-8920-c946beb34d6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of k-NN: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Шаг 4: Глубокое обучение (MLP)"
      ],
      "metadata": {
        "id": "LDOAvAYdlJZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0zBdZh6v9Jc",
        "outputId": "f24cc743-b712-4a00-f6f3-a409b8900ae5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.4911 - val_accuracy: 0.9533 - val_loss: 0.1575\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9637 - loss: 0.1190 - val_accuracy: 0.9647 - val_loss: 0.1127\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9752 - loss: 0.0786 - val_accuracy: 0.9734 - val_loss: 0.0884\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0521 - val_accuracy: 0.9693 - val_loss: 0.0948\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0427 - val_accuracy: 0.9733 - val_loss: 0.0947\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0351 - val_accuracy: 0.9722 - val_loss: 0.0974\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0268 - val_accuracy: 0.9758 - val_loss: 0.0874\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0194 - val_accuracy: 0.9691 - val_loss: 0.1167\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0215 - val_accuracy: 0.9737 - val_loss: 0.1056\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0123 - val_accuracy: 0.9729 - val_loss: 0.1106\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1048\n",
            "Accuracy of MLP: 0.9743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Шаг 5: Нейронные сети (CNN)"
      ],
      "metadata": {
        "id": "NOiLdfyJ4BmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsd4GgAt4D4W",
        "outputId": "3d185949-6832-4ab0-ecb3-77bb87f49aa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 37ms/step - accuracy: 0.8130 - loss: 0.5715 - val_accuracy: 0.9796 - val_loss: 0.0635\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 36ms/step - accuracy: 0.9644 - loss: 0.1155 - val_accuracy: 0.9848 - val_loss: 0.0495\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.9728 - loss: 0.0875 - val_accuracy: 0.9858 - val_loss: 0.0456\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - accuracy: 0.9774 - loss: 0.0714 - val_accuracy: 0.9869 - val_loss: 0.0435\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.9811 - loss: 0.0628 - val_accuracy: 0.9880 - val_loss: 0.0390\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.9821 - loss: 0.0564 - val_accuracy: 0.9883 - val_loss: 0.0348\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.9845 - loss: 0.0501 - val_accuracy: 0.9897 - val_loss: 0.0334\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 35ms/step - accuracy: 0.9862 - loss: 0.0451 - val_accuracy: 0.9904 - val_loss: 0.0317\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - accuracy: 0.9864 - loss: 0.0430 - val_accuracy: 0.9908 - val_loss: 0.0292\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 35ms/step - accuracy: 0.9876 - loss: 0.0394 - val_accuracy: 0.9907 - val_loss: 0.0300\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0324\n",
            "Accuracy of CNN: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Теоритические вопросы\n",
        "\n",
        "**Какие преимущества и недостатки использованных методов вы увидели?**\n",
        "\n",
        "   **Метод k-ближайших соседей (k-nearest neighbour, k-NN)**: популярный алгоритм классификации суть которого проста: посмотри на соседей вокруг, какие из них преобладают, таковым ты и являешься. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. Преимуществом метода прежде всего является нечувствительность к выбросам, он достаточно прост и компактен, нет необходимости строить модель, настраивать параметры и делать дополнительные допущения. Алгоритм универсален. Его можно использовать для обоих типов задач: классификации и регрессии. К недостаткам метода следует отнести его вычислительную ресурсоемкость, алгоритм работает значительно медленнее при увеличении объема выборки, предикторов или независимых переменных. К тому-же всегда  нужно определять оптимальное значение k.\n",
        "   \n",
        "   **Обычные нейронные сети (MLP)**: MLP чаще всего используются для обработки данных с фиксированными размерами, такими как таблицы данных или векторы признаков, а также для задач классификации, регрессии и прогнозирования. MLP имеют много параметров, особенно если они содержат много слоев и нейронов, что может привести к высокой вычислительной сложности и рискам переобучения, особенно при обучении на малом количестве данных.\n",
        "\n",
        "   **Сверточные нейронные сети (CNN)**: CNN специально разработаны для работы с многомерными данными, такими как изображения или видео, которые имеют структуру сетки пикселей. Они хорошо справляются с обработкой изображений, распознаванием объектов, сегментацией, классификацией и другими задачами компьютерного зрения. CNN обладают относительно меньшим количеством параметров, так как каждый нейрон сверточного слоя использует одни и те же веса для обработки различных участков изображения. Это позволяет более эффективно использовать данные и уменьшить риск переобучения.\n",
        "\n",
        "\n",
        "\n",
        "**В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?**\n",
        "\n",
        "По базовой организации они имеют один принцип - оба метода состоят из взаимосвязанных нейронов, которые обрабатывают данные через три или более уровней. Глубокая нейронная сеть (DNN) - это просто искусственная нейронная сеть с глубокими слоями. Глубокие слои в данном контексте означают, что сеть состоит из нескольких слоев, сложенных вместе для обработки и обучения на основе данных. MLP считается примером DNN - базовая структура MLP состоит из входного слоя, одного или нескольких скрытых слоев и выходного слоя. MLP является развитием базового персептрона и способная обрабатывать как линейно разделяемые, так и нелинейно разделяемые данные (отличия решений задачи AND/OR и  XOR).\n",
        "\n",
        "Различия между многослойным персептроном и глубокой нейронной сетью в том, что Многослойный персептрон имеет небольшое количество скрытых слоев и, соответственно, короткое время обучения, Глубокая же нейронная сеть имеет большее количество скрытых слоев и более длительное время обучения.\n",
        "\n",
        "\n",
        "**Какие методы предобработки данных были использованы в этом задании?**\n",
        "\n",
        "Для работы использовался ресурс https://www.openml.org/, в частности база данных рукописных цифр MNIST с 784 признаками. Это подмножество бОльшего набора, доступного от NIST ( http://yann.lecun.com/exdb/mnist/). Цифры нормализованы по размеру и центрированы в изображении фиксированного размера. Изображения уже центрированы в изображении 28x28 путем вычисления центра масс пикселей и перевода изображения таким образом, чтобы поместить эту точку в центр поля 28x28. Так что в части предобработки была произведена только конвертиртация меток в целочисленные значения и разделение данных на обучающую и тестовую выборки. Приемущество использования таких баз очевидно, но произошедший технический ицидент (https://github.com/openml/openml.org/issues/343) подтвердил приоритет использования для решения практических задач более надежных собственных подготовленных примеров.\n"
      ],
      "metadata": {
        "id": "btv9T5AY7Hvj"
      }
    }
  ]
}